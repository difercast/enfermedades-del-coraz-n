---
title: "Práctica 2"
author: "Diego Castillo"
date: "4/6/2019"
output: html_document
---

Carga de librerías necesarias para el desarrollo de la práctica.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, include=FALSE}
library(dplyr)
library(tseries)
library(grDevices)
library(ggplot2)
library(moments)
library(nortest)
library(tidyr)
library(car)
library(caret)
library(pROC)
```

## Descripción del Data set
El dataset escogido para el desarrollo de la práctica se denomina *Heart Disease Data Set* o conjunto de datos de enfermedades cardiacas. Este dataset se encuentra disponible en repositorio de datos de Kaggle en el siguiente [enlace](https://www.kaggle.com/ronitf/heart-disease-uci).

El conjunto de datos consta de un total de 14 atributos entre discretos y contínuos que recojen información básica de pacientes como edad, sexo y también almacena el resultado de un conjunto de exámenes realizados, obteniendo por ejemplo el nivel de colesterol en la sangre, nivel de azúcar en la sangre, etc.

Los atributos que conforman el conjunto de datos son:

- *age* Edad del paciente
- *sex* Sexo del paciente
- *cp* Tipo de dolor en el pecho
- *trestbps* Presión arterial en reposo
- *chol* Suero colestoral 
- *fbs* Glucemia en ayunas
- *restecg* Resultados electrocardiográficos en reposo
- *thalach* Ritmo cardiaco máximo alcanzado
- *exang* Angina inducida por el ejercicio
- *oldpeak* Depresión ST inducida por el ejercicio en relación con el descanso
- *slope* La pendiente del segmento pico del ejercicio ST
- *ca* Número de vasos principales (0-3) coloreados por fluoroscopia
- *thal* 3 = normal; 6 = defecto fijo; 7 = defecto reversible
- *target* Variable predictora

El conjunto de datos contiene información relevante de pacientes acerca de su actividad cardiaca recogidos mediante exámenes, así como también atributos como sexo y edad. Esta información permite resolver el problema de la detección temprana de enfermedades del corazón utilizando los atributos del dataset que permitan realizar la predicción de estas enfermedades.

## Integración y selección de los datos de interés a analizar.

Se realiza la carga del conjunto de datos y se consulta una porción de los mismos con el fin de observar si estos se han cargado de manera correcta.
```{r}
# Se fija el espacio de trabajo
setwd("C:/Users/dell/Dropbox/maestria/Tipología y ciclo de vida de los datos/Práctica 2")

# Carga de los datos
heart <- read.csv('heart.csv', header = FALSE)
names(heart) <- c("age","sex","cp","trestbps","chol","fbs","restecg","thalach","exang","oldpeak","slope","ca","thal","target")

# Revisión de los datos
head(heart)
```

Se utiliza el comando `summary` con el fin de observar algunas aestadísticas básicas del dataset.
```{r}
# Realizamos un análisis preliminar de los datos
summary(heart)

```
Se puede observar que el dataset contiene información de personas de 29 a 77 años con una media de edad de 55 años, la varaible *thalach* presenta el ritmo cardiaco máximo alcanzado por los pacientes cuyos valores van desde 71 a 202 pulsasiones por minuto, etc.

Uitlizamos también el comando `str` para observar la estructura del data set.
```{r}
# Revisamos de nuevo la estructura del dataset
str(heart)
```
Como resultado se tiene que todas las variables son numéricas, aunque algunas de ellas son discretas y se debe convertir en factores, como la variable `sex` que contiene valores que corresponden a 0= mujer y 1 = hombre, la variable `cp` cuyos valores van de 0 a 3 dependiendo del tipo del dolor en el pecho, el atributo `fbs` que toma el valor 0 si no presenta glucemia en ayunas y el valor 1 cuando si presenta, la variable `restecg` recoge los resultados de los exámenes electrocardigráficos en reposos que van de 0 a 3, la variable `exang` toma valores de 0 a 1 si se presenta angina inducidad por ejercicio, la variable `slope` toma valres de 0 a 2 de acuerdo a la pendiente del segmento del ejercicio, `ca` almacena el número de vasos principales que van desde 0 a 3,  y `thal` cuyos valores van de 0 a 3 si presenta algún defecto.

Por lo visto, se realiza el cambio a factores de las variables discretas.
```{r}
# Cambiamos los valores correspondiente a mujeres y hombres en la varaible sex
heart <- heart %>% mutate(sex=ifelse(sex==1,"hombre","mujer"))

# Factorizamos las variables discretas.
cols<-c("sex","cp","fbs","restecg","exang","slope","ca","thal","target")
for (i in cols){
  heart[,i] <- as.factor(heart[,i])
}
```

Luego de transformar los atributos a factores, revisamos de nuevo la estructura de los datos para confirmarlo.
```{r}
str(heart)
```

## Limpieza de los datos.

### ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?

Al tratarse de valores numéricos, no se realizará el análisis o identificación de valores iguales a 0 ya que al revisar el significado de cada variable, nos damos cuenta que las variables que contienen valores iguales a 0 son resultados de exámenes aplicados a los pacientes, y que, según el caso pueden ser iguales a 0.  

Los siguiente comandos realizan la indentificación de los valores que son nulos y también los valores que se encentran vacíos dentro del dataset.
```{r}
# Identificamos valores nulos
sapply(heart,function(x) sum(is.na(x)))

# Se realiza la búsqueda de elementos que contengan valores vacios
colSums(heart =="")
```

Como resultado de los comandos ejecutados, se tiene que los atributos del dataset no contienen valores nulos ni tampoco valores vacios

En el supuesto caso en que se tuviera atributos que contengan valores nulos o vacíos, la eficacia de las técnicas de tratamiento de estos valores está directamente relacionada con la razón por la cual tuvo su origen el valor perdido. Si tenemos alguna información acerca de ella, es posible que encontremos una regla para completar estos valores, por el contrario, si no tenemos dicha información, es necesario aplicar técnicas de evaluación de los valores perdidos que encuentren algún patrón que permita ya sea completarlos o descartarlos(en el caso que no afecten el análisis),decisión que depende en gran medida del tipo del valor perdido y la importancia del registro en la base de datos (Allison,2001).

### Identificación y tratamiento de valores extremos.
Se entiende por valores extremos o `outliers` a aquellas observaciones que se desvían mucho de otras observaciones y despierta sospechas de ser generadas por mecanismos diferentes.

En la presente práctica analizaremos los siguientes atributos continuos en busca de outliers: `trestbps`, `chol`, `thalach` y `oldpeak`.

**Nota:** Al tratarse de resultados de exámenes realizados a pacientes, es muy normal encontrar valores desorbitados o fuera de lo normal en algunos de ellos, debido a diferentes causas como alimentación, ejercicio físico, estilo de vida, etc. Por ello, los outliers de este dataset no deberían ser corregidos. Únicamente por motivos didácticos correspondientes a la práctica se realizará la corrección de estos valores extremos

**trestbps**

Como se indicó anteriormente, el atributo `trestbps` hace referencia a la presión aterial en reposo del paciente, primero se grafica el conjunto de datos para este atributos, con el fin de detectar outliers.
```{r}
# Graficamos en busca de outliers
boxplot(heart$trestbps,main = "Presión arterial",boxwex = 0.5,col="blue")
```

Se puede observar que existen valores extremos, por lo que se procede a su corrección, para estos casos vamos a imputar los outliers reemplazando el valor de los outliers por la media de la variable `trestbps`.
```{r}
# Realizamos la imputación de los outliers
imputar_outliers <- function(x, removeNA = TRUE){
  quantiles <- quantile(x, c(0.05, 0.95), na.rm = removeNA)
  x[x<quantiles[1]] <- mean(x, na.rm = removeNA)
  x[x>quantiles[2]] <- median(x, na.rm = removeNA)
  x
}

trestbps_imputada <- imputar_outliers(heart$trestbps)
```

Por últimos, realizamos las comparación de los valores de la varaible `trestbps` con y sin outliers.
```{r}
#Graficamos las diferencias
par(mfrow = c(1,2))
boxplot(heart$trestbps, main = "Presión arterial con outliers",
        col = 3)
boxplot(trestbps_imputada, main = "Presión arterial sin outliers",col=2)

# Actualizamos los valores correctos
heart$trestbps <- trestbps_imputada 
```


**chol**

Siguiendo con el desarrollo de la práctica, realizamos el análisis de la variable `chol`, la cual contiene el valor del suero colesteral de los pacientes. Primero revisamos si existen outliers.
```{r}
# Graficamos en busca de outliers
boxplot(heart$chol,main = "Suero colesteral",boxwex = 0.5,col="blue")
```

Al evidenciar que efectivamente se tienen valores extremos, se procede con la corrección de los mismos utilizando la función desarrollada en la anterior sección.
```{r}
# Realizamos la imputación de los outliers
chol_imputada <- imputar_outliers(heart$chol)
```

Por últimos, realizamos las comparación de los valores de la varaible `chol` con y sin outliers.
```{r}
#Graficamos las diferencias
par(mfrow = c(1,2))
boxplot(heart$chol, main = "Suero colesteral con outliers",
        col = 3)
boxplot(chol_imputada, main = "Suero colesteral sin outliers",col=2)

# Actualizamos los valores correctos
heart$chol <- chol_imputada
```


**thalach**

La variable thalach almacena el ritmo cardiaco máximo al canzado por los pacientes. en esta variable continua también se analiza si se cuenta con outliers.
```{r}
# Graficamos en busca de outliers
boxplot(heart$thalach,main = "Ritmo cardiaco",boxwex = 0.5,col="blue")
```

Solo existe un valor extremos, al cual también se corregirá.
```{r}
# Realizamos la imputación de los outliers
thalach_imputada <- imputar_outliers(heart$thalach)
```

Se realiza comprobación de los datos con y sin outliers.
```{r}
#Graficamos las diferencias
par(mfrow = c(1,2))
boxplot(heart$thalach, main = "Ritmo cardiaco con outliers",
        col = 3)
boxplot(thalach_imputada, main = "Ritmo cardiaco sin outliers",col=2)

# Actualizamos los valores del atributo
heart$thalach <- thalach_imputada
```

**oldpeak**

Esta última variable continua contiene la depresión ST inducida por el ejercicio en relación con el descanso, y se procede con el análisis de la misma en busca de outiers.
```{r}
# Graficamos en busca de outliers
boxplot(heart$oldpeak,main = "Drepresión ST",boxwex = 0.5,col="blue")
```

Se realiza la corrección de los outliers detectados, utilizando la imputación.
```{r}
# Realizamos la imputación de los outliers
oldpeak_imputada <- imputar_outliers(heart$oldpeak)
```

Se realiza comprobación de los datos con y sin outliers.
```{r}
#Graficamos las diferencias
par(mfrow = c(1,2))
boxplot(heart$oldpeak, main = "Depresión ST con outliers",
        col = 3)
boxplot(oldpeak_imputada, main = "Depresión ST sin outliers",col=2)

# Actualizamos los valores del atributo
heart$oldpeak <- oldpeak_imputada
```


## Análisis de los datos
### Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).


### Comprobación de la normalidad y homogeneidad de la varianza 

#### Comprobación de la normalidad

En muchos trabajos y publicaciones se ha visto que en los análisis estadísticos que se realizan, suponen que las variables continuas siguen una distribución normal sin antes realizar una verificación previa. 

En la presente sección de sealizará la comprovación primero visual y luego mediante la aplicación del test de nomralidad denominado de `asimetría`, ya que es uno de los más recomendados.

Las variables a las que se aplicarán estos test son:`trestbps`, `chol`, `thalach` y `oldpeak`.

**Análisis visual**

Utilizando un histograma se puede analizar de manera visual la distribución que siguen los datos y así determinar su normalidad.

```{r}
heart %>%
  gather(Attributes, value, trestbps,chol,thalach,oldpeak) %>%
  ggplot(aes(x=value)) +
  geom_histogram(fill="lightblue2", colour="black") +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Frequency") +
  theme_bw()
```
Se puede determinar que por lo menos visualmente, los atributos `chol` y `trstbps` siguen una distribución parecida a la normal. 

Realizamos el test de normalidad sobre los atributos, utilizando el test de asimetría.
```{r}
skewness(heart$trestbps)
skewness(heart$chol)
skewness(heart$thalach)
skewness(heart$oldpeak)
```
Se logra determinar que ninguna de las variable sigue una distribución normal.

#### Homogeneidad de la varianza
El supuesto de homogeneidad de varianzas, conocido también como *homocedasticidad*, considera que la varianza es constante en los diferentes niveles de un factor, es decir, entre diferentes grupos.

Existen diferentes tests que permiten evaluar la distribución del a varianza. Todos ellos consideran como hipótesos nula que la varianza es igual entre los grupos y como hipotesis alternativa que no lo es.La diferencia entre ellos es el estádistico de centralidad que utilizan: media, mediana, media truncada. Een nuestro ejemplo las variables no tienen una distribución normal por lo que se utilizará el *Test de Levene*, cual se caracteriza por utilizar la mediana  y por no depender de la distribución de las variables.

Se revisa la homogeneidad de los atribtos de tipo factores para los valores de la variable `trestbps`.

Para anlaizar los resultados obtenidos, realizamos la formulación de las hipótesis, en donde, la *Hipótesis nula* no dice que existe homogeneidad entre las varianzas, en cambio la *hipótesis alterna* indica que las varianzas son diferentes.

Para tomar la decisión nos basamos en el valor de `p`, en donde, si `p<0.05` entonces rechazamos la hipótesis nula y nos quedamos con la hipótesis del investigador.

```{r}

# age
leveneTest(y = heart$trestbps, group = heart$age, center = "median")
# Sex
leveneTest(y = heart$trestbps, group = heart$sex, center = "median")
# cp
leveneTest(y = heart$trestbps, group = heart$cp, center = "median")
# fbs
leveneTest(y = heart$trestbps, group = heart$fbs, center = "median")
# restecg
leveneTest(y = heart$trestbps, group = heart$restecg, center = "median")
# exang
leveneTest(y = heart$trestbps, group = heart$exang, center = "median")
# ca
leveneTest(y = heart$trestbps, group = heart$ca, center = "median")
# slope
leveneTest(y = heart$trestbps, group = heart$slope, center = "median")
# thal
leveneTest(y = heart$trestbps, group = heart$thal, center = "median")
```
Según los resultados obtenidos, se tiene que únicamente la variable `fbs` no cumple con el novel de significancia por lo que se considera que su varianza es diferente. En el resto de variables nos quedamos con la hipótesis nula o que existe homogeneidad de varianza.

### Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo de estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos 3 métodos de análisis diferentes.

#### Regresión logística
Para aplicar la regresión logística, creamos un nuevo dataset en el cual únicamente se encuentren las variables discretas o de tipo factor y luego dividimos el conjunto de datos en dos partes, una parte `train` y la otra `test`. Asignando el 70% de los datos pertenecerán al grupo test y el restante 30% al grupo de entrenamiento.
```{r}
# Creamos un nuevo dataset únicamente con las variables necesarias
set.seed(10)
inTrainRows <- createDataPartition(heart$target,p=0.7,list=FALSE)
trainData <- heart[inTrainRows,]
testData <-  heart[-inTrainRows,]
nrow(trainData)/(nrow(testData)+nrow(trainData))

# Modelo de regresión logística
set.seed(10)
logRegModel <- train(target ~ ., data=trainData, method = 'glmnet', family = 'binomial')
logRegPrediction <- predict(logRegModel, testData)
logRegPredictionprob <- predict(logRegModel, testData, type='prob')[2]
logRegConfMat <- confusionMatrix(logRegPrediction, testData[,"target"])

logRegConfMat
```

### Clasificación utilizando el método random forest

```{r}
library(randomForest)
set.seed(10)
RFModel <- randomForest(target ~ .,
                    data=trainData,
                    importance=TRUE,
                    ntree=2000)
#varImpPlot(RFModel)
RFPrediction <- predict(RFModel, testData)
RFPredictionprob = predict(RFModel,testData,type="prob")[, 2]

RFConfMat <- confusionMatrix(RFPrediction, testData[,"target"])
RFConfMat

AUC$RF <- roc(as.numeric(testData$num),as.numeric(as.matrix((RFPredictionprob))))$auc
Accuracy$RF <- RFConfMat$overall['Accuracy']  
```

### Clasificación utilizando el método Support Vector Machine

